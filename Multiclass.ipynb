{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec46662-6110-475d-aada-7a218e3ac51b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5276056e-bafb-4e4e-88f8-ab938d698d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "sns.set_palette(\"tab20\")\n",
    "\n",
    "#!pip install imblearn\n",
    "# !pip uninstall scikit-learn\n",
    "# !pip install scikit-learn==1.2.2\n",
    "#from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import  LogisticRegression, SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, ComplementNB\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import category_encoders as ce\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "sns.set_palette(\"tab20\")\n",
    "\n",
    "random_state = 42\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2814622-38cb-46da-b3cd-4868577bfb24",
   "metadata": {},
   "source": [
    "## Additional Preprocessing for Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c06b2f5-713e-4713-a138-1c6b61b5dea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Data/df_train_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "547f60c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding for multiclass variable\n",
    "mapping = {'No': 0, '>30 days': 1, '<30 days': 2}\n",
    "df_train['readmitted_multiclass'] = df_train['readmitted_multiclass'].map(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9444cf8",
   "metadata": {},
   "source": [
    "### Admission_Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1518f999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill NA's with Unknown\n",
    "df_train['admission_source'] = df_train['admission_source'].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd7d1e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.539123\n",
       "1    0.349276\n",
       "2    0.111601\n",
       "Name: readmitted_multiclass, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the overall proportion for each class in 'readmitted_multiclass'\n",
    "overall_proportion = df_train['readmitted_multiclass'].value_counts(normalize=True)\n",
    "overall_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7be8a32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>readmitted_multiclass</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admission_source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Court/Law Enforcement</th>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emergency Room</th>\n",
       "      <td>0.506982</td>\n",
       "      <td>0.376398</td>\n",
       "      <td>0.116620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extramural Birth</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not Available</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.147727</td>\n",
       "      <td>0.079545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physician Referral</th>\n",
       "      <td>0.569881</td>\n",
       "      <td>0.324935</td>\n",
       "      <td>0.105184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sick Baby</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transfer from Ambulatory Surgery Center</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transfer from a Skilled Nursing Facility (SNF)</th>\n",
       "      <td>0.589916</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.127731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transfer from another health care facility</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.175416</td>\n",
       "      <td>0.097311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transfer from critial access hospital</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transfer from hospital inpt/same fac reslt in a sep claim</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clinic Referral</th>\n",
       "      <td>0.608472</td>\n",
       "      <td>0.286264</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HMO Referral</th>\n",
       "      <td>0.519380</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.155039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normal Delivery</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transfer from a hospital</th>\n",
       "      <td>0.695067</td>\n",
       "      <td>0.208969</td>\n",
       "      <td>0.095964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>0.520415</td>\n",
       "      <td>0.372021</td>\n",
       "      <td>0.107565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "readmitted_multiclass                                      0         1  \\\n",
       "admission_source                                                         \n",
       " Court/Law Enforcement                              0.636364  0.181818   \n",
       " Emergency Room                                     0.506982  0.376398   \n",
       " Extramural Birth                                   1.000000  0.000000   \n",
       " Not Available                                      0.772727  0.147727   \n",
       " Physician Referral                                 0.569881  0.324935   \n",
       " Sick Baby                                          1.000000  0.000000   \n",
       " Transfer from Ambulatory Surgery Center            1.000000  0.000000   \n",
       " Transfer from a Skilled Nursing Facility (SNF)     0.589916  0.282353   \n",
       " Transfer from another health care facility         0.727273  0.175416   \n",
       " Transfer from critial access hospital              0.857143  0.142857   \n",
       " Transfer from hospital inpt/same fac reslt in ...  0.625000  0.250000   \n",
       "Clinic Referral                                     0.608472  0.286264   \n",
       "HMO Referral                                        0.519380  0.325581   \n",
       "Normal Delivery                                     1.000000  0.000000   \n",
       "Transfer from a hospital                            0.695067  0.208969   \n",
       "Unknown                                             0.520415  0.372021   \n",
       "\n",
       "readmitted_multiclass                                      2  \n",
       "admission_source                                              \n",
       " Court/Law Enforcement                              0.181818  \n",
       " Emergency Room                                     0.116620  \n",
       " Extramural Birth                                   0.000000  \n",
       " Not Available                                      0.079545  \n",
       " Physician Referral                                 0.105184  \n",
       " Sick Baby                                          0.000000  \n",
       " Transfer from Ambulatory Surgery Center            0.000000  \n",
       " Transfer from a Skilled Nursing Facility (SNF)     0.127731  \n",
       " Transfer from another health care facility         0.097311  \n",
       " Transfer from critial access hospital              0.000000  \n",
       " Transfer from hospital inpt/same fac reslt in ...  0.125000  \n",
       "Clinic Referral                                     0.105263  \n",
       "HMO Referral                                        0.155039  \n",
       "Normal Delivery                                     0.000000  \n",
       "Transfer from a hospital                            0.095964  \n",
       "Unknown                                             0.107565  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the proportion of each class within each 'admission_source' and create columns\n",
    "counts_per_admission_source = df_train.groupby(['admission_source', 'readmitted_multiclass']).size()\n",
    "total_counts_per_admission_source = df_train['admission_source'].value_counts()\n",
    "admission_source_proportion = counts_per_admission_source.div(total_counts_per_admission_source, level='admission_source').unstack(fill_value=0)\n",
    "admission_source_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4c672a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Emergency Room                                               40319\n",
       " Physician Referral                                           20678\n",
       "Unknown                                                        4825\n",
       "Transfer from a hospital                                       2230\n",
       " Transfer from another health care facility                    1562\n",
       "Clinic Referral                                                 779\n",
       " Transfer from a Skilled Nursing Facility (SNF)                 595\n",
       "HMO Referral                                                    129\n",
       " Not Available                                                   88\n",
       " Court/Law Enforcement                                           11\n",
       " Transfer from hospital inpt/same fac reslt in a sep claim        8\n",
       " Transfer from critial access hospital                            7\n",
       " Transfer from Ambulatory Surgery Center                          2\n",
       " Extramural Birth                                                 1\n",
       "Normal Delivery                                                   1\n",
       " Sick Baby                                                        1\n",
       "Name: admission_source, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['admission_source'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91af7876",
   "metadata": {},
   "source": [
    "Group all small categories into 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aa5669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_source_proportion_reset = admission_source_proportion.reset_index()\n",
    "df_train = df_train.merge(admission_source_proportion_reset, on='admission_source', how='left')\n",
    "\n",
    "df_train.rename(columns={0: 'admission_source_0', 1:'admission_source_1', 2:'admission_source_2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8ca846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create bins comparing the average of readmitted multiclass and the average of each class in admission source\n",
    "df_train['admission_source_0_high'] = df_train['admission_source_0'].apply(lambda x: 1 \n",
    "                                                                           if x >= 0.6\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['admission_source_0_low'] = df_train['admission_source_0'].apply(lambda x: 1 \n",
    "                                                                           if x < 0.5\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['admission_source_1_high'] = df_train['admission_source_1'].apply(lambda x: 1 \n",
    "                                                                           if x >= 0.4\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['admission_source_1_low'] = df_train['admission_source_1'].apply(lambda x: 1 \n",
    "                                                                           if x < 0.3\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['admission_source_2_high'] = df_train['admission_source_2'].apply(lambda x: 1 \n",
    "                                                                           if x >= 0.12\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['admission_source_2_low'] = df_train['admission_source_2'].apply(lambda x: 1 \n",
    "                                                                           if x < 0.1\n",
    "                                                                            else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a694157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    66546\n",
      "1     4690\n",
      "Name: admission_source_0_high, dtype: int64\n",
      "0    71236\n",
      "Name: admission_source_0_low, dtype: int64\n",
      "0    71236\n",
      "Name: admission_source_1_high, dtype: int64\n",
      "0    65951\n",
      "1     5285\n",
      "Name: admission_source_1_low, dtype: int64\n",
      "0    70493\n",
      "1      743\n",
      "Name: admission_source_2_high, dtype: int64\n",
      "0    67344\n",
      "1     3892\n",
      "Name: admission_source_2_low, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train['admission_source_0_high'].value_counts())\n",
    "print(df_train['admission_source_0_low'].value_counts())\n",
    "print(df_train['admission_source_1_high'].value_counts())\n",
    "print(df_train['admission_source_1_low'].value_counts())\n",
    "print(df_train['admission_source_2_high'].value_counts())\n",
    "print(df_train['admission_source_2_low'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e2be36-473a-4371-9305-4eade18a6986",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Medical_specialty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e970f0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing missing values in 'medical_specialty' with a placeholder 'Unknown'\n",
    "df_train['medical_specialty'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faf382e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>readmitted_multiclass</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_specialty</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AllergyandImmunology</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anesthesiology</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anesthesiology-Pediatric</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cardiology</th>\n",
       "      <td>0.572659</td>\n",
       "      <td>0.347955</td>\n",
       "      <td>0.079386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cardiology-Pediatric</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surgery-Thoracic</th>\n",
       "      <td>0.614458</td>\n",
       "      <td>0.289157</td>\n",
       "      <td>0.096386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surgery-Vascular</th>\n",
       "      <td>0.498630</td>\n",
       "      <td>0.353425</td>\n",
       "      <td>0.147945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SurgicalSpecialty</th>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>0.518441</td>\n",
       "      <td>0.365701</td>\n",
       "      <td>0.115858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urology</th>\n",
       "      <td>0.635983</td>\n",
       "      <td>0.267782</td>\n",
       "      <td>0.096234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "readmitted_multiclass            0         1         2\n",
       "medical_specialty                                     \n",
       "AllergyandImmunology      0.166667  0.333333  0.500000\n",
       "Anesthesiology            0.800000  0.200000  0.000000\n",
       "Anesthesiology-Pediatric  0.666667  0.333333  0.000000\n",
       "Cardiology                0.572659  0.347955  0.079386\n",
       "Cardiology-Pediatric      0.200000  0.600000  0.200000\n",
       "...                            ...       ...       ...\n",
       "Surgery-Thoracic          0.614458  0.289157  0.096386\n",
       "Surgery-Vascular          0.498630  0.353425  0.147945\n",
       "SurgicalSpecialty         0.640000  0.280000  0.080000\n",
       "Unknown                   0.518441  0.365701  0.115858\n",
       "Urology                   0.635983  0.267782  0.096234\n",
       "\n",
       "[69 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the proportion of each class within each 'medical_specialty' and create columns\n",
    "counts_per_medical_specialty = df_train.groupby(['medical_specialty', 'readmitted_multiclass']).size()\n",
    "total_counts_per_medical_specialty = df_train['medical_specialty'].value_counts()\n",
    "medical_specialty_proportion = counts_per_medical_specialty.div(total_counts_per_medical_specialty, level='medical_specialty').unstack(fill_value=0)\n",
    "medical_specialty_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ac7d259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset the index\n",
    "medical_specialty_proportion_reset = medical_specialty_proportion.reset_index()\n",
    "df_train = df_train.merge(medical_specialty_proportion_reset, on='medical_specialty', how='left')\n",
    "\n",
    "#rename the columns\n",
    "df_train.rename(columns={0: 'medical_specialty_0', 1: 'medical_specialty_1', 2: 'medical_specialty_2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47aa7f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create bins comparing the proportion of each readmitted multiclass and the proportion of each class in medical specialty\n",
    "df_train['medical_specialty_0_high'] = df_train['medical_specialty_0'].apply(lambda x: 1 \n",
    "                                                                           if x >= 0.6\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['medical_specialty_0_low'] = df_train['medical_specialty_0'].apply(lambda x: 1 \n",
    "                                                                           if x < 0.5\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['medical_specialty_1_high'] = df_train['medical_specialty_1'].apply(lambda x: 1 \n",
    "                                                                           if x >= 0.4\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['medical_specialty_1_low'] = df_train['medical_specialty_1'].apply(lambda x: 1 \n",
    "                                                                           if x < 0.3\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['medical_specialty_2_high'] = df_train['medical_specialty_2'].apply(lambda x: 1 \n",
    "                                                                           if x >= 0.12\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['medical_specialty_2_low'] = df_train['medical_specialty_2'].apply(lambda x: 1 \n",
    "                                                                           if x < 0.1\n",
    "                                                                            else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dfd0ee-8100-42e2-82e5-9904abe0d9c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Discharge_disposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5f8b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['discharge_disposition'] = df_train['discharge_disposition'].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06b67b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>readmitted_multiclass</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discharge_disposition</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Admitted as an inpatient to this hospital</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged to home</th>\n",
       "      <td>0.550099</td>\n",
       "      <td>0.357156</td>\n",
       "      <td>0.092744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred to ICF</th>\n",
       "      <td>0.532399</td>\n",
       "      <td>0.343257</td>\n",
       "      <td>0.124343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred to SNF</th>\n",
       "      <td>0.499387</td>\n",
       "      <td>0.354397</td>\n",
       "      <td>0.146217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred to a federal health care facility.</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred to a long term care hospital.</th>\n",
       "      <td>0.592857</td>\n",
       "      <td>0.332143</td>\n",
       "      <td>0.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred to a nursing facility certified under Medicaid but not certified under Medicare.</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred to another rehab fac including rehab units of a hospital .</th>\n",
       "      <td>0.468055</td>\n",
       "      <td>0.253410</td>\n",
       "      <td>0.278536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred to another short term hospital</th>\n",
       "      <td>0.524194</td>\n",
       "      <td>0.310484</td>\n",
       "      <td>0.165323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred to another type of inpatient care institution</th>\n",
       "      <td>0.507299</td>\n",
       "      <td>0.283455</td>\n",
       "      <td>0.209246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred to home under care of Home IV provider</th>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.382716</td>\n",
       "      <td>0.123457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred to home with home health service</th>\n",
       "      <td>0.457190</td>\n",
       "      <td>0.416435</td>\n",
       "      <td>0.126374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred within this institution to Medicare approved swing bed</th>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.386364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred/referred another institution for outpatient services</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred/referred to a psychiatric hospital of psychiatric distinct part unit of a hospital</th>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred/referred to this institution for outpatient services</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Expired</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Expired at home. Medicaid only, hospice.</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Expired in a medical facility. Medicaid only, hospice.</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hospice / home</th>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.089147</td>\n",
       "      <td>0.042636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hospice / medical facility</th>\n",
       "      <td>0.923372</td>\n",
       "      <td>0.015326</td>\n",
       "      <td>0.061303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Left AMA</th>\n",
       "      <td>0.486936</td>\n",
       "      <td>0.365796</td>\n",
       "      <td>0.147268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neonate discharged to another hospital for neonatal aftercare</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Still patient or expected to return for outpatient services</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>0.581523</td>\n",
       "      <td>0.297033</td>\n",
       "      <td>0.121444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "readmitted_multiclass                                      0         1  \\\n",
       "discharge_disposition                                                    \n",
       "Admitted as an inpatient to this hospital           0.384615  0.076923   \n",
       "Discharged to home                                  0.550099  0.357156   \n",
       "Discharged/transferred to ICF                       0.532399  0.343257   \n",
       "Discharged/transferred to SNF                       0.499387  0.354397   \n",
       "Discharged/transferred to a federal health care...  1.000000  0.000000   \n",
       "Discharged/transferred to a long term care hosp...  0.592857  0.332143   \n",
       "Discharged/transferred to a nursing facility ce...  0.500000  0.343750   \n",
       "Discharged/transferred to another rehab fac inc...  0.468055  0.253410   \n",
       "Discharged/transferred to another short term ho...  0.524194  0.310484   \n",
       "Discharged/transferred to another type of inpat...  0.507299  0.283455   \n",
       "Discharged/transferred to home under care of Ho...  0.493827  0.382716   \n",
       "Discharged/transferred to home with home health...  0.457190  0.416435   \n",
       "Discharged/transferred within this institution ...  0.318182  0.295455   \n",
       "Discharged/transferred/referred another institu...  0.428571  0.571429   \n",
       "Discharged/transferred/referred to a psychiatri...  0.387755  0.214286   \n",
       "Discharged/transferred/referred to this institu...  0.750000  0.250000   \n",
       "Expired                                             1.000000  0.000000   \n",
       "Expired at home. Medicaid only, hospice.            1.000000  0.000000   \n",
       "Expired in a medical facility. Medicaid only, h...  1.000000  0.000000   \n",
       "Hospice / home                                      0.868217  0.089147   \n",
       "Hospice / medical facility                          0.923372  0.015326   \n",
       "Left AMA                                            0.486936  0.365796   \n",
       "Neonate discharged to another hospital for neon...  0.500000  0.500000   \n",
       "Still patient or expected to return for outpati...  0.500000  0.000000   \n",
       "Unknown                                             0.581523  0.297033   \n",
       "\n",
       "readmitted_multiclass                                      2  \n",
       "discharge_disposition                                         \n",
       "Admitted as an inpatient to this hospital           0.538462  \n",
       "Discharged to home                                  0.092744  \n",
       "Discharged/transferred to ICF                       0.124343  \n",
       "Discharged/transferred to SNF                       0.146217  \n",
       "Discharged/transferred to a federal health care...  0.000000  \n",
       "Discharged/transferred to a long term care hosp...  0.075000  \n",
       "Discharged/transferred to a nursing facility ce...  0.156250  \n",
       "Discharged/transferred to another rehab fac inc...  0.278536  \n",
       "Discharged/transferred to another short term ho...  0.165323  \n",
       "Discharged/transferred to another type of inpat...  0.209246  \n",
       "Discharged/transferred to home under care of Ho...  0.123457  \n",
       "Discharged/transferred to home with home health...  0.126374  \n",
       "Discharged/transferred within this institution ...  0.386364  \n",
       "Discharged/transferred/referred another institu...  0.000000  \n",
       "Discharged/transferred/referred to a psychiatri...  0.397959  \n",
       "Discharged/transferred/referred to this institu...  0.000000  \n",
       "Expired                                             0.000000  \n",
       "Expired at home. Medicaid only, hospice.            0.000000  \n",
       "Expired in a medical facility. Medicaid only, h...  0.000000  \n",
       "Hospice / home                                      0.042636  \n",
       "Hospice / medical facility                          0.061303  \n",
       "Left AMA                                            0.147268  \n",
       "Neonate discharged to another hospital for neon...  0.000000  \n",
       "Still patient or expected to return for outpati...  0.500000  \n",
       "Unknown                                             0.121444  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same logic as before, calculate the proportion of each class within each 'discharge_disposition' and create columns accordingly\n",
    "counts_per_discharge_disposition = df_train.groupby(['discharge_disposition', 'readmitted_multiclass']).size()\n",
    "total_counts_per_discharge_disposition = df_train['discharge_disposition'].value_counts()\n",
    "\n",
    "discharge_disposition_proportion = counts_per_discharge_disposition.div(total_counts_per_discharge_disposition, level='discharge_disposition').unstack(fill_value=0)\n",
    "discharge_disposition_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc326dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>readmitted_multiclass</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discharge_disposition</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Admitted as an inpatient to this hospital</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged to home</th>\n",
       "      <td>23245.0</td>\n",
       "      <td>15092.0</td>\n",
       "      <td>3919.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred to ICF</th>\n",
       "      <td>304.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred to SNF</th>\n",
       "      <td>4884.0</td>\n",
       "      <td>3466.0</td>\n",
       "      <td>1430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred to a federal health care facility.</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred to a long term care hospital.</th>\n",
       "      <td>166.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred to a nursing facility certified under Medicaid but not certified under Medicare.</th>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred to another rehab fac including rehab units of a hospital .</th>\n",
       "      <td>652.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>388.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred to another short term hospital</th>\n",
       "      <td>780.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred to another type of inpatient care institution</th>\n",
       "      <td>417.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred to home under care of Home IV provider</th>\n",
       "      <td>40.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred to home with home health service</th>\n",
       "      <td>4117.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>1138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred within this institution to Medicare approved swing bed</th>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred/referred another institution for outpatient services</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred/referred to a psychiatric hospital of psychiatric distinct part unit of a hospital</th>\n",
       "      <td>38.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discharged/transferred/referred to this institution for outpatient services</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Expired</th>\n",
       "      <td>1135.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Expired at home. Medicaid only, hospice.</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Expired in a medical facility. Medicaid only, hospice.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hospice / home</th>\n",
       "      <td>224.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hospice / medical facility</th>\n",
       "      <td>241.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Left AMA</th>\n",
       "      <td>205.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neonate discharged to another hospital for neonatal aftercare</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Still patient or expected to return for outpatient services</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>1901.0</td>\n",
       "      <td>971.0</td>\n",
       "      <td>397.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "readmitted_multiclass                                     0        1       2\n",
       "discharge_disposition                                                       \n",
       "Admitted as an inpatient to this hospital               5.0      1.0     7.0\n",
       "Discharged to home                                  23245.0  15092.0  3919.0\n",
       "Discharged/transferred to ICF                         304.0    196.0    71.0\n",
       "Discharged/transferred to SNF                        4884.0   3466.0  1430.0\n",
       "Discharged/transferred to a federal health care...      3.0      NaN     NaN\n",
       "Discharged/transferred to a long term care hosp...    166.0     93.0    21.0\n",
       "Discharged/transferred to a nursing facility ce...     16.0     11.0     5.0\n",
       "Discharged/transferred to another rehab fac inc...    652.0    353.0   388.0\n",
       "Discharged/transferred to another short term ho...    780.0    462.0   246.0\n",
       "Discharged/transferred to another type of inpat...    417.0    233.0   172.0\n",
       "Discharged/transferred to home under care of Ho...     40.0     31.0    10.0\n",
       "Discharged/transferred to home with home health...   4117.0   3750.0  1138.0\n",
       "Discharged/transferred within this institution ...     14.0     13.0    17.0\n",
       "Discharged/transferred/referred another institu...      3.0      4.0     NaN\n",
       "Discharged/transferred/referred to a psychiatri...     38.0     21.0    39.0\n",
       "Discharged/transferred/referred to this institu...      6.0      2.0     NaN\n",
       "Expired                                              1135.0      NaN     NaN\n",
       "Expired at home. Medicaid only, hospice.                6.0      NaN     NaN\n",
       "Expired in a medical facility. Medicaid only, h...      1.0      NaN     NaN\n",
       "Hospice / home                                        224.0     23.0    11.0\n",
       "Hospice / medical facility                            241.0      4.0    16.0\n",
       "Left AMA                                              205.0    154.0    62.0\n",
       "Neonate discharged to another hospital for neon...      1.0      1.0     NaN\n",
       "Still patient or expected to return for outpati...      1.0      NaN     1.0\n",
       "Unknown                                              1901.0    971.0   397.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['discharge_disposition', 'readmitted_multiclass']].groupby(['discharge_disposition', 'readmitted_multiclass']).value_counts().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8854b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "discharge_disposition_proportion_reset = discharge_disposition_proportion.reset_index()\n",
    "\n",
    "df_train = df_train.merge(discharge_disposition_proportion_reset, on='discharge_disposition', how='left')\n",
    "\n",
    "df_train.rename(columns={0: 'discharge_disposition_0', 1: 'discharge_disposition_1', 2: 'discharge_disposition_2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c905bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create bins comparing the proportion of each readmitted multiclass and the proportion of each class in discharge disposition\n",
    "df_train['discharge_disposition_0_high'] = df_train['discharge_disposition_0'].apply(lambda x: 1 \n",
    "                                                                           if x >= 0.6\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['discharge_disposition_0_low'] = df_train['discharge_disposition_0'].apply(lambda x: 1 \n",
    "                                                                           if x < 0.5\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['discharge_disposition_1_high'] = df_train['discharge_disposition_1'].apply(lambda x: 1 \n",
    "                                                                           if x >= 0.4\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['discharge_disposition_1_low'] = df_train['discharge_disposition_1'].apply(lambda x: 1 \n",
    "                                                                           if x < 0.3\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['discharge_disposition_2_high'] = df_train['discharge_disposition_2'].apply(lambda x: 1 \n",
    "                                                                           if x >= 0.12\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['discharge_disposition_2_low'] = df_train['discharge_disposition_2'].apply(lambda x: 1 \n",
    "                                                                           if x < 0.1\n",
    "                                                                            else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6adb7636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    69564\n",
      "1     1672\n",
      "Name: discharge_disposition_0_high, dtype: int64\n",
      "0    50394\n",
      "1    20842\n",
      "Name: discharge_disposition_0_low, dtype: int64\n",
      "0    62222\n",
      "1     9014\n",
      "Name: discharge_disposition_1_high, dtype: int64\n",
      "0    63923\n",
      "1     7313\n",
      "Name: discharge_disposition_1_low, dtype: int64\n",
      "0    44217\n",
      "1    27019\n",
      "Name: discharge_disposition_2_high, dtype: int64\n",
      "1    44217\n",
      "0    27019\n",
      "Name: discharge_disposition_2_low, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train['discharge_disposition_0_high'].value_counts())\n",
    "print(df_train['discharge_disposition_0_low'].value_counts())\n",
    "print(df_train['discharge_disposition_1_high'].value_counts())\n",
    "print(df_train['discharge_disposition_1_low'].value_counts())\n",
    "print(df_train['discharge_disposition_2_high'].value_counts())\n",
    "print(df_train['discharge_disposition_2_low'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20afea9",
   "metadata": {},
   "source": [
    "### Diagnosis variables "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2c99a0",
   "metadata": {},
   "source": [
    "Primary Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "989c8c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>readmitted_multiclass</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>primary_diagnosis</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.350877</td>\n",
       "      <td>0.192982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V56</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V57</th>\n",
       "      <td>0.512167</td>\n",
       "      <td>0.351101</td>\n",
       "      <td>0.136732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V58</th>\n",
       "      <td>0.286667</td>\n",
       "      <td>0.313333</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V63</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V71</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>686 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "readmitted_multiclass         0         1         2\n",
       "primary_diagnosis                                  \n",
       "10                     1.000000  0.000000  0.000000\n",
       "11                     0.857143  0.142857  0.000000\n",
       "110                    0.000000  1.000000  0.000000\n",
       "112                    0.456140  0.350877  0.192982\n",
       "114                    0.000000  1.000000  0.000000\n",
       "...                         ...       ...       ...\n",
       "V56                    0.500000  0.416667  0.083333\n",
       "V57                    0.512167  0.351101  0.136732\n",
       "V58                    0.286667  0.313333  0.400000\n",
       "V63                    0.800000  0.200000  0.000000\n",
       "V71                    0.666667  0.333333  0.000000\n",
       "\n",
       "[686 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#same logic as before, calculate the proportion of each class within each 'primary diagnosis' and create columns accordingly\n",
    "counts_per_primary_diagnosis = df_train.groupby(['primary_diagnosis', 'readmitted_multiclass']).size()\n",
    "total_counts_per_primary_diagnosis = df_train['primary_diagnosis'].value_counts()\n",
    "\n",
    "primary_diagnosis_proportion = counts_per_primary_diagnosis.div(total_counts_per_primary_diagnosis, level='primary_diagnosis').unstack(fill_value=0)\n",
    "primary_diagnosis_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b8e8a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_diagnosis_proportion_reset = primary_diagnosis_proportion.reset_index()\n",
    "\n",
    "df_train = df_train.merge(primary_diagnosis_proportion_reset, on='primary_diagnosis', how='left')\n",
    "\n",
    "df_train.rename(columns={0: 'primary_diagnosis_0', 1: 'primary_diagnosis_1', 2: 'primary_diagnosis_2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e193e2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create bins comparing the proportion of each readmitted multiclass and the proportion of each class in primary diagnosis\n",
    "df_train['primary_diagnosis_0_high'] = df_train['primary_diagnosis_0'].apply(lambda x: 1 \n",
    "                                                                           if x >= 0.6\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['primary_diagnosis_0_low'] = df_train['primary_diagnosis_0'].apply(lambda x: 1 \n",
    "                                                                           if x < 0.5\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['primary_diagnosis_1_high'] = df_train['primary_diagnosis_1'].apply(lambda x: 1 \n",
    "                                                                           if x >= 0.4\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['primary_diagnosis_1_low'] = df_train['primary_diagnosis_1'].apply(lambda x: 1 \n",
    "                                                                           if x < 0.3\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['primary_diagnosis_2_high'] = df_train['primary_diagnosis_2'].apply(lambda x: 1 \n",
    "                                                                           if x >= 0.12\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['primary_diagnosis_2_low'] = df_train['primary_diagnosis_2'].apply(lambda x: 1 \n",
    "                                                                           if x < 0.1\n",
    "                                                                            else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a074eff6",
   "metadata": {},
   "source": [
    "Secondary Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6259606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>readmitted_multiclass</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>secondary_diagnosis</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.521429</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.135714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V69</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V70</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V72</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V85</th>\n",
       "      <td>0.628319</td>\n",
       "      <td>0.247788</td>\n",
       "      <td>0.123894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V86</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>698 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "readmitted_multiclass         0         1         2\n",
       "secondary_diagnosis                                \n",
       "11                     0.333333  0.333333  0.333333\n",
       "110                    0.428571  0.428571  0.142857\n",
       "111                    1.000000  0.000000  0.000000\n",
       "112                    0.521429  0.342857  0.135714\n",
       "114                    0.000000  0.000000  1.000000\n",
       "...                         ...       ...       ...\n",
       "V69                    1.000000  0.000000  0.000000\n",
       "V70                    0.600000  0.400000  0.000000\n",
       "V72                    0.800000  0.200000  0.000000\n",
       "V85                    0.628319  0.247788  0.123894\n",
       "V86                    0.000000  1.000000  0.000000\n",
       "\n",
       "[698 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same logic as before, calculate the proportion of each class within each 'discharge_disposition' and create columns accordingly\n",
    "counts_per_secondary_diagnosis = df_train.groupby(['secondary_diagnosis', 'readmitted_multiclass']).size()\n",
    "total_counts_per_secondary_diagnosis = df_train['secondary_diagnosis'].value_counts()\n",
    "\n",
    "secondary_diagnosis_proportion = counts_per_secondary_diagnosis.div(total_counts_per_secondary_diagnosis, level='secondary_diagnosis').unstack(fill_value=0)\n",
    "secondary_diagnosis_proportion_reset = secondary_diagnosis_proportion.reset_index()\n",
    "secondary_diagnosis_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "518ad586",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.merge(secondary_diagnosis_proportion_reset, on='secondary_diagnosis', how='left')\n",
    "\n",
    "df_train.rename(columns={0: 'secondary_diagnosis_0', 1: 'secondary_diagnosis_1', 2: 'secondary_diagnosis_2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf190792",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create bins comparing the proportion of each readmitted multiclass and the proportion of each class in primary diagnosis\n",
    "df_train['secondary_diagnosis_0_high'] = df_train['secondary_diagnosis_0'].apply(lambda x: 1 \n",
    "                                                                           if x >= 0.6\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['secondary_diagnosis_0_low'] = df_train['secondary_diagnosis_0'].apply(lambda x: 1 \n",
    "                                                                           if x < 0.5\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['secondary_diagnosis_1_high'] = df_train['secondary_diagnosis_1'].apply(lambda x: 1 \n",
    "                                                                           if x >= 0.4\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['secondary_diagnosis_1_low'] = df_train['secondary_diagnosis_1'].apply(lambda x: 1 \n",
    "                                                                           if x < 0.3\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['secondary_diagnosis_2_high'] = df_train['secondary_diagnosis_2'].apply(lambda x: 1 \n",
    "                                                                           if x >= 0.12\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['secondary_diagnosis_2_low'] = df_train['secondary_diagnosis_2'].apply(lambda x: 1 \n",
    "                                                                           if x < 0.1\n",
    "                                                                            else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d85eaee",
   "metadata": {},
   "source": [
    "Additional Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d94c801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>readmitted_multiclass</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>additional_diagnosis</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.539007</td>\n",
       "      <td>0.361702</td>\n",
       "      <td>0.099291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V66</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V70</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V72</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V85</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.231884</td>\n",
       "      <td>0.101449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V86</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>746 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "readmitted_multiclass         0         1         2\n",
       "additional_diagnosis                               \n",
       "11                     0.500000  0.000000  0.500000\n",
       "110                    0.666667  0.250000  0.083333\n",
       "112                    0.539007  0.361702  0.099291\n",
       "115                    1.000000  0.000000  0.000000\n",
       "117                    0.200000  0.400000  0.400000\n",
       "...                         ...       ...       ...\n",
       "V66                    0.666667  0.250000  0.083333\n",
       "V70                    1.000000  0.000000  0.000000\n",
       "V72                    0.666667  0.166667  0.166667\n",
       "V85                    0.666667  0.231884  0.101449\n",
       "V86                    0.500000  0.500000  0.000000\n",
       "\n",
       "[746 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same logic as before, calculate the proportion of each class within each 'additional_diagnosis' and create columns accordingly\n",
    "counts_per_additional_diagnosis = df_train.groupby(['additional_diagnosis', 'readmitted_multiclass']).size()\n",
    "total_counts_per_additional_diagnosis = df_train['additional_diagnosis'].value_counts()\n",
    "\n",
    "additional_diagnosis_proportion = counts_per_additional_diagnosis.div(total_counts_per_additional_diagnosis, level='additional_diagnosis').unstack(fill_value=0)\n",
    "additional_diagnosis_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a19e8ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "additional_diagnosis_proportion_reset = additional_diagnosis_proportion.reset_index()\n",
    "\n",
    "df_train = df_train.merge(additional_diagnosis_proportion_reset, on='additional_diagnosis', how='left')\n",
    "\n",
    "df_train.rename(columns={0: 'additional_diagnosis_0', 1: 'additional_diagnosis_1', 2: 'additional_diagnosis_2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d117d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create bins comparing the proportion of each readmitted multiclass and the proportion of each class in primary diagnosis\n",
    "df_train['additional_diagnosis_0_high'] = df_train['additional_diagnosis_0'].apply(lambda x: 1 \n",
    "                                                                           if x >= 0.6\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['additional_diagnosis_0_low'] = df_train['additional_diagnosis_0'].apply(lambda x: 1 \n",
    "                                                                           if x < 0.5\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['additional_diagnosis_1_high'] = df_train['additional_diagnosis_1'].apply(lambda x: 1 \n",
    "                                                                           if x >= 0.4\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['additional_diagnosis_1_low'] = df_train['additional_diagnosis_1'].apply(lambda x: 1 \n",
    "                                                                           if x < 0.3\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['additional_diagnosis_2_high'] = df_train['additional_diagnosis_2'].apply(lambda x: 1 \n",
    "                                                                           if x >= 0.12\n",
    "                                                                            else 0)\n",
    "\n",
    "df_train['additional_diagnosis_2_low'] = df_train['additional_diagnosis_2'].apply(lambda x: 1 \n",
    "                                                                           if x < 0.1\n",
    "                                                                            else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42087c7e-7887-48c2-98bc-ef74eb3f244b",
   "metadata": {},
   "source": [
    "## Model and feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ebfd31-109d-4ac5-908e-a865a37ccbd7",
   "metadata": {},
   "source": [
    "### Set train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d35057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#replace columns names \n",
    "\n",
    "categorical_columns = ['race',\n",
    "       'payer_code',  'admission_type',\n",
    "       'medical_specialty',  'discharge_disposition',\n",
    "       'admission_source', 'primary_diagnosis',\n",
    "       'secondary_diagnosis', 'additional_diagnosis', \n",
    "       'change_in_meds_during_hospitalization', 'prescribed_diabetes_meds',\n",
    "       # 'readmitted_binary', 'readmitted_multiclass',\n",
    "       'has_weight', 'race_Asian', 'race_Caucasian', 'race_Hispanic',\n",
    "       'race_Other', 'race_nan', 'payer_code_HM', 'payer_code_MC',\n",
    "       'payer_code_MD', 'payer_code_No provider', 'payer_code_Other provider',\n",
    "       'payer_code_SP', \n",
    "       'more_than_one_lab_test', 'high_admission_source',\n",
    "       'medium_admission_source', 'low_admission_source',\n",
    "       'admission_type_big_share', 'admission_type_big_share_Elective',\n",
    "       'admission_type_big_share_Emergency', 'admission_type_big_share_Urgent',\n",
    "       'no_medical_specialty', 'high_medical_specialty',\n",
    "       'medium_medical_specialty', 'low_medical_specialty',\n",
    "       'discharged_home_hospice', 'expired', 'very_high_discharge_disposition', 'high_discharge_disposition',\n",
    "       'medium_discharge_disposition', 'primary_diagnosis_category',\n",
    "       'secondary_diagnosis_category', 'additional_diagnosis_category',\n",
    "       'high_primary_diagnosis_category', 'medium_primary_diagnosis_category',\n",
    "       'low_primary_diagnosis_category', 'high_secondary_diagnosis_category',\n",
    "       'medium_secondary_diagnosis_category',\n",
    "       'low_secondary_diagnosis_category',\n",
    "       'high_additional_diagnosis_category',\n",
    "       'medium_additional_diagnosis_category',\n",
    "       'low_additional_diagnosis_category', 'diabetes_diagnosis',\n",
    "       'diabetes_diagnosis_4_digits', 'diabetes_type',\n",
    "       'diabetes_severity_group', 'diabetes_severity_group_Mild',\n",
    "       'diabetes_severity_group_Moderate', 'diabetes_severity_group_Severe',\n",
    "       'diabetes_type_I - controlled', 'diabetes_type_I - uncontrolled',\n",
    "       'diabetes_type_II - controlled', 'diabetes_type_II - uncontrolled',\n",
    "       'glucose_test_performed', 'a1c_test_performed', \n",
    "       'metformin', 'rosiglitazone', 'glyburide', 'insulin', 'glipizide',\n",
    "       'repaglinide', 'glimepiride', 'pioglitazone',\n",
    "        'high_primary_diagnosis',\n",
    "       'medium_primary_diagnosis', 'low_primary_diagnosis',\n",
    "       'high_secondary_diagnosis', 'medium_secondary_diagnosis',\n",
    "       'low_secondary_diagnosis', 'high_additional_diagnosis',\n",
    "       'medium_additional_diagnosis', 'low_additional_diagnosis']\n",
    "\n",
    "df_train[categorical_columns] = df_train[categorical_columns].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3b198a8f-eafe-4c50-ac77-e643596efca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_use = ['encounter_id', 'patient_id', \n",
    "                  \n",
    "                  'gender', 'age', 'has_weight',\n",
    "                  \n",
    "                  'outpatient_visits_in_previous_year',\n",
    "                  'emergency_visits_in_previous_year',\n",
    "                  'inpatient_visits_in_previous_year', \n",
    "                  'total_visits', 'max_visits_of_one_type',\n",
    "                  \n",
    "                  'average_pulse_bpm', \n",
    "                  'length_of_stay_in_hospital', \n",
    "\n",
    "                  'medical_specialty_0_high', 'medical_specialty_0_low', 'medical_specialty_1_high', \n",
    "                  'medical_specialty_1_low', 'medical_specialty_2_high', 'medical_specialty_2_low',\n",
    "\n",
    "                  'admission_source_0_high',\t'admission_source_0_low',\t'admission_source_1_high',\t'admission_source_1_low',\n",
    "                  'admission_source_2_high',\t'admission_source_2_low',\n",
    "\n",
    "                  'discharge_disposition_0_high', 'discharge_disposition_0_low',\n",
    "                  'discharge_disposition_1_high', 'discharge_disposition_1_low',\n",
    "                  'discharge_disposition_2_high', 'discharge_disposition_2_low',\n",
    "                  \n",
    "                  'primary_diagnosis_2_low', 'primary_diagnosis_2_high','primary_diagnosis_1_low',\n",
    "                  'primary_diagnosis_1_high','primary_diagnosis_0_low','primary_diagnosis_0_high',\n",
    "\n",
    "                  'secondary_diagnosis_2_low', 'secondary_diagnosis_2_high','secondary_diagnosis_1_low',\n",
    "                  'secondary_diagnosis_1_high','secondary_diagnosis_0_low','secondary_diagnosis_0_high',                   \n",
    "                   \n",
    "                  'additional_diagnosis_0_high', 'additional_diagnosis_0_low',\n",
    "                  'additional_diagnosis_1_high', 'additional_diagnosis_1_low',\n",
    "                  'additional_diagnosis_2_high', 'additional_diagnosis_2_low',\n",
    "                                \n",
    "                  'number_lab_tests',\n",
    "                  'non_lab_procedures', \n",
    "                  'number_of_medications', \n",
    "                  'number_diagnoses',\n",
    "                  \n",
    "                  'glucose_test_performed', 'glucose_test_result',\n",
    "                   'a1c_test_result',\n",
    "        \n",
    "                  'change_in_meds_during_hospitalization', \n",
    "                  'prescribed_diabetes_meds', \n",
    "                  \n",
    "                  'race_Asian', 'race_Caucasian', 'race_Hispanic',\n",
    "                  'race_Other', 'race_nan', \n",
    "                  \n",
    "                  'payer_code_No provider',\n",
    "                  'payer_code_Other provider',        \n",
    "                   \n",
    "                  'diabetes_severity_group_Mild', 'diabetes_severity_group_Moderate', 'diabetes_severity_group_Severe',\n",
    "                  \n",
    "                  'diabetes_type_I - controlled', 'diabetes_type_I - uncontrolled',\n",
    "                  'diabetes_type_II - controlled', 'diabetes_type_II - uncontrolled',\n",
    "                  \n",
    "                  'glimepiride', 'pioglitazone', 'repaglinide', 'metformin', 'glyburide',\n",
    "                  'rosiglitazone', 'glipizide', 'insulin']\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c5a1e1f4-786a-4afe-9bf6-7c07a5d7a965",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_train[columns_to_use]\n",
    "target = df_train['readmitted_multiclass']\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbc0f59",
   "metadata": {},
   "source": [
    "### Functions for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "48c3d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encoder(fit_data, transform_data, target, features_for_encoding, smoothing=100):\n",
    "    target_encoder = ce.TargetEncoder(cols=features_for_encoding, smoothing=smoothing)  \n",
    "    target_encoder.fit(fit_data[features_for_encoding], fit_data[target].astype(int))\n",
    "    encoded_df = target_encoder.transform(transform_data[features_for_encoding])\n",
    "    features_for_encoding_pass = [i + '_target' for i in features_for_encoding]\n",
    "    transform_data[features_for_encoding_pass] = np.array(encoded_df)\n",
    "    encoded_df = transform_data.drop(columns = features_for_encoding)\n",
    "    # encoded_df =  pd.concat((transform_data[transform_data.columns.difference(features_for_encoding)],\n",
    "    #                     pd.DataFrame(np.array(encoded_df), columns = features_for_encoding_pass)), axis=1)\n",
    "    return encoded_df, features_for_encoding_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3641bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler(fit_data, transform_data, features_for_scaling, scaling_type = 'minmax'):\n",
    "    if scaling_type == 'minmax':\n",
    "        sc = MinMaxScaler()\n",
    "        sc.fit(fit_data[features_for_scaling])\n",
    "        scaled_df = sc.transform(transform_data[features_for_scaling])\n",
    "        scaled_df = pd.concat((transform_data[transform_data.columns.difference(features_for_scaling)],\n",
    "                        pd.DataFrame(scaled_df, columns = features_for_scaling)), axis=1) \n",
    "        return scaled_df\n",
    "    if scaling_type == 'standard':\n",
    "        sc = StandardScaler()\n",
    "        sc.fit(fit_data[features_for_scaling])\n",
    "        scaled_df = sc.transform(transform_data[features_for_scaling])\n",
    "        scaled_df = pd.concat((transform_data[transform_data.columns.difference(features_for_scaling)],\n",
    "                        pd.DataFrame(scaled_df, columns = features_for_scaling)), axis=1)\n",
    "        return scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9492a5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patient_features(df_train, df_test, multiclass = False):\n",
    "    df_all = pd.concat([df_train, df_test])\n",
    "\n",
    "    list_for_scaling = []\n",
    "    \n",
    "    # total visits of one patient in dataset, excluding current visit\n",
    "    patient_total_visits = df_train[['patient_id', 'encounter_id']].groupby('patient_id').count().rename(columns={'encounter_id': 'patient_total_visits'}).reset_index()\n",
    "    patient_total_visits['patient_total_visits'] = (patient_total_visits['patient_total_visits'] - 1).astype('int')\n",
    "    df_train = pd.merge(df_train, patient_total_visits, how = 'left', on = 'patient_id')\n",
    "    df_train['patient_total_visits'].fillna(0, inplace = True)\n",
    "\n",
    "    patient_total_visits = df_all[['patient_id', 'encounter_id']].groupby('patient_id').count().rename(columns={'encounter_id': 'patient_total_visits'}).reset_index()\n",
    "    patient_total_visits['patient_total_visits'] = (patient_total_visits['patient_total_visits'] - 1).astype('int')\n",
    "    df_test = pd.merge(df_test, patient_total_visits, how = 'left', on = 'patient_id')\n",
    "    df_test['patient_total_visits'].fillna(0, inplace = True)\n",
    "\n",
    "    list_for_scaling.append('patient_total_visits')\n",
    "\n",
    "    if multiclass == False:\n",
    "        # check if we know that this person was readmitted on any other visit we know and calculate number of readmissions\n",
    "        was_readmitted_encounter = df_train[['patient_id', \n",
    "                                   'encounter_id',\n",
    "                                   'readmitted_binary']].groupby(['patient_id','encounter_id']).max(numeric_only=True).rename(columns={'readmitted_binary': 'was_readmitted_encounter'}).reset_index()\n",
    "        was_readmitted_patient = df_train[['patient_id', \n",
    "                                       'readmitted_binary']].groupby(['patient_id']).sum(numeric_only=True).rename(columns={'readmitted_binary': 'was_readmitted_patient'}).reset_index()\n",
    "        was_readmitted = pd.merge(was_readmitted_encounter, was_readmitted_patient, on = 'patient_id')\n",
    "        was_readmitted['patient_num_readmitted'] = (was_readmitted['was_readmitted_patient'] - was_readmitted['was_readmitted_encounter']).astype('int')\n",
    "        was_readmitted['patient_was_readmitted'] = was_readmitted['patient_num_readmitted'].apply(lambda x: 1 if x > 0 else 0).astype('category')\n",
    "        df_train = pd.merge(df_train, was_readmitted[['patient_num_readmitted', 'patient_was_readmitted', 'encounter_id']], how = 'left', on = 'encounter_id')\n",
    "        df_train[['patient_num_readmitted', 'patient_was_readmitted']] = df_train[['patient_num_readmitted', 'patient_was_readmitted']].fillna(0)\n",
    "    \n",
    "        df_test = pd.merge(df_test, was_readmitted[['patient_num_readmitted', 'patient_was_readmitted', 'encounter_id']], how = 'left', on = 'encounter_id')\n",
    "        df_test[['patient_num_readmitted', 'patient_was_readmitted']] = df_test[['patient_num_readmitted', 'patient_was_readmitted']].fillna(0).astype(int)\n",
    "        list_for_scaling.append('patient_num_readmitted')\n",
    "\n",
    "    return df_train, df_test, list_for_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "48947a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsampler(data, \n",
    "              target,  \n",
    "              upsample_type = 'simple', \n",
    "              upsample_size = 1):\n",
    "    majority_class_label = data[target].value_counts().idxmax()\n",
    "    minority_class_labels = data[target].value_counts().index.drop(majority_class_label)\n",
    "    balanced_data = pd.DataFrame()\n",
    "    if upsample_type == 'simple':\n",
    "        for label in minority_class_labels:\n",
    "            if len(data[data[target] == majority_class_label])*upsample_size > len(data[data[target] == label]):\n",
    "                minority_upsampled = resample(data[data[target] == label], replace=True, n_samples=int(len(data[data[target] == majority_class_label])*upsample_size), \n",
    "                                                  random_state = random_state)\n",
    "                balanced_data = pd.concat([balanced_data, minority_upsampled])\n",
    "            else:\n",
    "                balanced_data = pd.concat([balanced_data, data[data[target] == label]])\n",
    "        balanced_data = pd.concat([balanced_data, data[data[target] == majority_class_label]])\n",
    "    if upsample_type == 'SMOTE':\n",
    "        X = data.drop(columns = target)\n",
    "        categorical_features = X.select_dtypes(include='category').columns\n",
    "        cat_ind = [X.columns.get_loc(col) for col in categorical_features]\n",
    "        smote_nc = SMOTENC(categorical_features=cat_ind, random_state=random_state)\n",
    "        X_resampled, y_resampled = smote_nc.fit_resample(X, data[target])  \n",
    "        balanced_data = pd.concat([X_resampled, y_resampled], axis = 1)\n",
    "    return balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "95a6131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(data, \n",
    "                     target, \n",
    "                     model, \n",
    "                     params, \n",
    "                     multiclass = False,\n",
    "                     \n",
    "                     scaling = False,\n",
    "                     features_for_scaling_minmax = [],\n",
    "                     features_for_scaling_standard = [],\n",
    "\n",
    "                     target_encoding = False,\n",
    "                     features_for_encoding = [],\n",
    "                     smoothing = 100,\n",
    "                     \n",
    "                     upsample = False, \n",
    "                     upsample_size = 1,\n",
    "                     upsample_type = 'simple', \n",
    "                     cv=5\n",
    "                     ):\n",
    "    # Defining some lists to collect data\n",
    "    feature_imp = []\n",
    "    f1 = []\n",
    "    confusion_matrix_list = []\n",
    "    precision_score_list = []\n",
    "    recall_score_list = []\n",
    "    roc_auc_score_list = []\n",
    "\n",
    "    # A bit of resampling just to mix data\n",
    "    data = data.sample(frac=1, random_state=random_state)\n",
    "    data[target] = data[target].astype(int)\n",
    "    \n",
    "\n",
    "    # create stratified folds\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle = True, random_state = random_state)\n",
    "    split = list(skf.split(data.drop(columns = target), data[target]))\n",
    "    all_train_index = [i[0] for i in split]\n",
    "    all_val_index = [i[1] for i in split]\n",
    "    \n",
    "    for i in tqdm(range(cv)):\n",
    "        val_index = all_val_index[i]\n",
    "        train_index = all_train_index[i]\n",
    "        train_data, val_data = data.loc[train_index], data.loc[val_index]\n",
    "\n",
    "        #Target encoding\n",
    "        if target_encoding == True:\n",
    "                val_data = target_encoder(train_data, val_data, features_for_encoding = features_for_encoding, target = target, smoothing = smoothing)[0]\n",
    "                train_data, features_for_encoding_pass = target_encoder(train_data, train_data, features_for_encoding = features_for_encoding, target = target, smoothing = smoothing)\n",
    "                features_for_scaling_minmax_full = features_for_scaling_minmax + list(features_for_encoding_pass)\n",
    "        else:\n",
    "            features_for_scaling_minmax_full = features_for_scaling_minmax\n",
    "\n",
    "        #creating features on patient level that we will use\n",
    "        train_data, val_data, pat_features_scale = patient_features(train_data, val_data, multiclass = multiclass)\n",
    "        features_for_scaling_minmax_full = features_for_scaling_minmax_full + pat_features_scale\n",
    " \n",
    "        # Scaling features\n",
    "        if scaling == True:\n",
    "            if len(features_for_scaling_minmax) > 0:\n",
    "                val_data = scaler(train_data, val_data, features_for_scaling_minmax_full, scaling_type = 'minmax')\n",
    "                train_data = scaler(train_data, train_data, features_for_scaling_minmax_full, scaling_type = 'minmax')\n",
    "            if len(features_for_scaling_standard) > 0:\n",
    "                val_data = scaler(train_data, val_data, features_for_scaling_standard, scaling_type = 'standard')\n",
    "                train_data = scaler(train_data, train_data, features_for_scaling_standard, scaling_type = 'standard')\n",
    "                \n",
    "        # Upsampling only train data \n",
    "        if upsample == True:\n",
    "            train_data = upsampler(train_data, target, upsample_type = upsample_type,  upsample_size = upsample_size)\n",
    "\n",
    "        # Defining train and val datasets\n",
    "        X_train = train_data.drop(target, axis=1).drop(columns = ['encounter_id', 'patient_id'])\n",
    "        y_train = train_data[target]\n",
    "        \n",
    "        X_val = val_data.drop(target, axis=1).drop(columns = ['encounter_id', 'patient_id'])\n",
    "        y_val = val_data[target]\n",
    "\n",
    "\n",
    "        # Fit and predict\n",
    "        model.set_params(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_val = model.predict(X_val)\n",
    "\n",
    "        #Feature importances if our model can do this\n",
    "        try:\n",
    "            try:\n",
    "                feature_imp.append(model.feature_importances_)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                feature_imp.append(model.coef_)\n",
    "            except:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Calculating f1 scores and other metrics\n",
    "        if multiclass == False:\n",
    "            f1.append([f1_score(y_train, y_pred_train), f1_score(y_val, y_pred_val)])\n",
    "            recall_score_list.append([recall_score(y_train, y_pred_train), recall_score(y_val, y_pred_val)])\n",
    "            precision_score_list.append([precision_score(y_train, y_pred_train), precision_score(y_val, y_pred_val)])\n",
    "            roc_auc_score_list.append([roc_auc_score(y_train, y_pred_train), roc_auc_score(y_val, y_pred_val)])\n",
    "        if multiclass == True:\n",
    "            f1.append([f1_score( y_train, y_pred_train, average = 'weighted'), f1_score(y_val, y_pred_val, average = 'weighted')])\n",
    "            recall_score_list.append([recall_score( y_train, y_pred_train, average = 'weighted'), recall_score(y_val, y_pred_val, average = 'weighted')])\n",
    "            precision_score_list.append([precision_score(y_train, y_pred_train, average = 'weighted'), precision_score(y_val, y_pred_val, average = 'weighted')])\n",
    "            # roc_auc_score_list.append([roc_auc_score( y_train, y_pred_train.reshape(-1, 1), multi_class='ovr', average = 'micro'), roc_auc_score(y_val, y_pred_val.reshape(-1, 1), multi_class='ovr', average = 'micro')])\n",
    "\n",
    "        \n",
    "        confusion_matrix_list.append([confusion_matrix(y_train, y_pred_train), confusion_matrix(y_val, y_pred_val)])\n",
    "\n",
    "    # Printing results\n",
    "    print(model)\n",
    "    print('F1 train: {:.3f}, F1_val: {:.3f}'.format(np.array(f1).mean(axis = 0)[0],\n",
    "                                                   np.array(f1).mean(axis = 0)[1]))\n",
    "    return [model.get_params(), \n",
    "            {'f1' : np.array(f1).mean(axis = 0), \n",
    "             'recall_score' : np.array(recall_score_list).mean(axis = 0),\n",
    "             'precision_score' : np.array(precision_score_list).mean(axis = 0),\n",
    "             'roc_auc_score' : np.array(roc_auc_score_list).mean(axis = 0)\n",
    "            }, \n",
    "            {'f1' : f1, \n",
    "             'recall_score' : recall_score_list,\n",
    "             'precision_score' : precision_score_list,\n",
    "             'roc_auc_score' : roc_auc_score_list,\n",
    "             'confusion_matrix': confusion_matrix_list\n",
    "            },\n",
    "            X_train.columns, \n",
    "            np.median(np.array(feature_imp), axis = 0),\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4510e5c-cfe1-4f99-92d9-5afdcfd4833d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Important functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028936c3-78c8-4de3-81d8-60e9ff1cb193",
   "metadata": {},
   "source": [
    "### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d50ffecd-07f9-41eb-abee-2acee119fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_for_scaling_minmax = ['outpatient_visits_in_previous_year',\n",
    "       'emergency_visits_in_previous_year',\n",
    "       'inpatient_visits_in_previous_year', 'total_visits',\n",
    "       'max_visits_of_one_type', 'average_pulse_bpm','length_of_stay_in_hospital',\n",
    "       'non_lab_procedures', 'number_diagnoses', 'glucose_test_result',\n",
    "       'a1c_test_result']\n",
    "features_for_scaling_standard = ['number_lab_tests', 'number_of_medications']\n",
    "\n",
    "data = pd.concat([X_train, y_train], axis = 1)\n",
    "data.reset_index(inplace = True)\n",
    "\n",
    "target = 'readmitted_multiclass'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996b03de",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ef0cd1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|█████████                                    | 1/5 [00:01<00:05,  1.49s/it]\u001b[A\n",
      " 40%|██████████████████                           | 2/5 [00:02<00:04,  1.46s/it]\u001b[A\n",
      " 60%|███████████████████████████                  | 3/5 [00:04<00:02,  1.47s/it]\u001b[A\n",
      " 80%|████████████████████████████████████         | 4/5 [00:05<00:01,  1.45s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:07<00:00,  1.46s/it]\u001b[A\n",
      "/var/folders/kk/jn6jnrpj6_30s05tyyfmmk9h0000gn/T/ipykernel_88291/407243714.py:119: RuntimeWarning: Mean of empty slice.\n",
      "  'roc_auc_score' : np.array(roc_auc_score_list).mean(axis = 0)\n",
      "/Users/antonkutsenko/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "  5%|██▏                                         | 1/20 [00:07<02:19,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=4, max_features=None, min_samples_leaf=18,\n",
      "                       min_samples_split=6, n_estimators=16, random_state=42)\n",
      "F1 train: 0.527, F1_val: 0.537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|█████████                                    | 1/5 [00:01<00:05,  1.47s/it]\u001b[A\n",
      " 40%|██████████████████                           | 2/5 [00:02<00:04,  1.47s/it]\u001b[A\n",
      " 60%|███████████████████████████                  | 3/5 [00:04<00:02,  1.48s/it]\u001b[A\n",
      " 80%|████████████████████████████████████         | 4/5 [00:07<00:01,  1.79s/it]\u001b[A\n",
      "  5%|██▏                                         | 1/20 [00:14<04:36, 14.53s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, values \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     18\u001b[0m     random_params[key] \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(values)\n\u001b[0;32m---> 19\u001b[0m result\u001b[38;5;241m.\u001b[39mappend(cross_validation(data, \n\u001b[1;32m     20\u001b[0m                  target, \n\u001b[1;32m     21\u001b[0m                  model,\n\u001b[1;32m     22\u001b[0m                  random_params,  \n\u001b[1;32m     23\u001b[0m                  multiclass \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     24\u001b[0m                  scaling \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     25\u001b[0m                  features_for_scaling_minmax \u001b[38;5;241m=\u001b[39m features_for_scaling_minmax,\n\u001b[1;32m     26\u001b[0m                  features_for_scaling_standard \u001b[38;5;241m=\u001b[39m features_for_scaling_standard,\n\u001b[1;32m     27\u001b[0m                  upsample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[1;32m     28\u001b[0m                  upsample_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     29\u001b[0m                  cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m))\n",
      "Cell \u001b[0;32mIn[70], line 79\u001b[0m, in \u001b[0;36mcross_validation\u001b[0;34m(data, target, model, params, multiclass, scaling, features_for_scaling_minmax, features_for_scaling_standard, target_encoding, features_for_encoding, smoothing, upsample, upsample_size, upsample_type, cv)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Fit and predict\u001b[39;00m\n\u001b[1;32m     78\u001b[0m model\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m---> 79\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     80\u001b[0m y_pred_train \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n\u001b[1;32m     81\u001b[0m y_pred_val \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m    474\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    475\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    476\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    477\u001b[0m )(\n\u001b[1;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    479\u001b[0m         t,\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[1;32m    481\u001b[0m         X,\n\u001b[1;32m    482\u001b[0m         y,\n\u001b[1;32m    483\u001b[0m         sample_weight,\n\u001b[1;32m    484\u001b[0m         i,\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[1;32m    486\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    487\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[1;32m    488\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[1;32m    489\u001b[0m     )\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    182\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 184\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    890\u001b[0m         X,\n\u001b[1;32m    891\u001b[0m         y,\n\u001b[1;32m    892\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    893\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state = random_state)\n",
    "params = {\n",
    "    'n_estimators': np.random.randint(10, 20, 10),\n",
    "    'max_depth': np.random.randint(1, 5, 10),\n",
    "    'min_samples_split': np.random.randint(2, 10, 10),\n",
    "    'min_samples_leaf': np.random.randint(5, 20, 10),\n",
    "    # 'bootstrap': [True, False],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'class_weight': ['balanced', 'balanced_subsample'],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    # 'max_leaf_nodes': [None, 10, 20]\n",
    "}\n",
    "\n",
    "result = []\n",
    "for i in tqdm(range(20)):\n",
    "    random_params = {}\n",
    "    for key, values in params.items():\n",
    "        random_params[key] = random.choice(values)\n",
    "    result.append(cross_validation(data, \n",
    "                     target, \n",
    "                     model,\n",
    "                     random_params,  \n",
    "                     multiclass = True,\n",
    "                     scaling = True,\n",
    "                     features_for_scaling_minmax = features_for_scaling_minmax,\n",
    "                     features_for_scaling_standard = features_for_scaling_standard,\n",
    "                     upsample = False, \n",
    "                     upsample_size = 1,\n",
    "                     cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec47c2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5531480457912444\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state = random_state)\n",
    "params = {\n",
    "    'n_estimators': np.random.randint(100, 200, 10),\n",
    "    'max_depth': np.random.randint(10, 20, 10),\n",
    "    'min_samples_split': np.random.randint(2, 10, 10),\n",
    "    'min_samples_leaf': np.random.randint(5, 20, 10),\n",
    "    # 'bootstrap': [True, False],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'class_weight': ['balanced', 'balanced_subsample'],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "    # 'max_leaf_nodes': [None, 10, 20]\n",
    "}\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_rf = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy as an example metric\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "\n",
    "print(f1_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d60f019",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5789e497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3786433311008068\n"
     ]
    }
   ],
   "source": [
    "lr_classifier = LogisticRegression(max_iter=900)\n",
    "lr_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_lr = lr_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy as an example metric\n",
    "f1_lr = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "\n",
    "print(f1_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf85766",
   "metadata": {},
   "source": [
    "**MLP CLassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e120776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2992154477669934\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create and train a Multi-layer Perceptron (MLP) classifier\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "mlp_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_mlp = mlp_classifier.predict(X_test)\n",
    "\n",
    "f1_mlp = f1_score(y_test, y_pred_mlp, average='weighted')\n",
    "\n",
    "print(f1_mlp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdab29c",
   "metadata": {},
   "source": [
    "**Decision Trees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e60373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49647508418342984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = dt_classifier.predict(X_test)\n",
    "\n",
    "f1_dt = f1_score(y_test, y_pred_dt, average='weighted')\n",
    "\n",
    "print(f1_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54a291d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
